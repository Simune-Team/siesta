#!/usr/bin/env python

# Should make it "backwards" compatible down to 2.6
from __future__ import print_function

# This small utility can save a scipy sparse
# matrix in a NetCDF-4 file readable by tbtrans
# and hence you can gain access to a transport code
# without having to code the essentials.
# However, this also means that you do need
# to follow some strict rules.
# In the following several classes are made available
# to ease the creation of TB models for TBtrans.

# class TBT_TB
#   this class handles the saving of the TB model.
#   It requires a geometry formatted as TBT_Geom
#   and two csr-formatted sparse matrices (H and S)
#   Call the function .save(fname)
#   to save a NetCDF-4 file readable by tbtrans.

# class TBT_Geom
#   Handles geometries and is a quite powerful geometry
#   handler.
#   It enables a user to construct repeated cells for
#   tbtrans.
#   Specifically it allows one to easily find the 
#   neighbours of certain atoms by this easy call:
#     idx = TBT_Geom.close_all(ia,(1.,2.,3.))
#   which returns 3 index arrays (len(idx) == 3) which specifies:
#     idx[0] : all atoms within <= 1. of atom ia
#     idx[1] : all atoms within <= 2. of atom ia, but farther
#              away than 1. (1. < xa[:,:] - xa[ia,:][None,:] <= 2.)
#     idx[2] : all atoms within <= 3. of atom ia, but farther
#              away than 2. (2. < xa[:,:] - xa[ia,:][None,:] <= 3.)
#   With this call it is extremely easy to get nearest neighbours
#   etc. from a simple geometry.
#   You can repeat or tile the structure by these calls:
#     new_Geom = TBT_Geom.tile((0,3),(2,2))
#   which takes the geometry and repeats the entire structure
#   3 times in the x-direction, then those repeated cells
#   2 times in the z-direction. (thus the total size will be
#   3*2 * TBT_Geom.na_u
#     TBT_Geom.repeat()
#   works in the same way but enables one to utilize
#   Bloch enabled electrodes.
#   You can also remove certain atoms from the structure,
#   just do:
#     new_Geom = TBT_Geom.remove(np.arange(3))
#   which removes the first 3 atoms.
#
#   NOTE: The geometry class expects coordinates in Ang.

# The difficult class
# class TB_Model
#   This class solely handles the assignment of TB parameters
#   for the model.
#   To create a model simply pass a TBT_Geom to the initialization.
#   and the object will be setup correspondingly.
#     model = TBT_Model(TBT_Geom())
#   The only thing you need to do now is assigning 
#   TB parameters to the model.
#     model[i,j] = (H,S) [ H should be in eV ]
#   will create a hopping integral between orbital i and j
#   As the model can use periodicity you also need to
#   create the supercell interactions (it will not do this
#   for you)
#   An easy way is to ask for which sets you should set is
#   to use the geometry object to retrieve the closest
#   atoms and from there create your orbitals.
#   This is extremely easy for single orbital atoms
#   whereas for N orbital atoms this is a little bit more
#   tricky.
#   See the below code for how to construct a TB model for
#   graphene.
#

# PLEASE
# !!!
# Do not edit this file without contributing 
# your edits to the community!
# What is helping you, could MOST likely also
# help others in the community!
# Respect the maintainer, the code and the other users.
# !!!

# Written by: Nick Papior Andersen, 2014

# Load needed modules
import copy, os, datetime
import itertools as it
import numpy as np
import netCDF4 as nc

class SIESTA_UNITS(object):
    """
    Object to retain all SIESTA relevant units
    """
    # constant fields for converting Ry/Bohr to eV/Ang
    # SIESTA/tbtrans requires Ry and Bohr
    Ry = 13.60580
    Bohr = 0.529177

class TBT_Geom(SIESTA_UNITS):
    """
    Geometry object handling atomic coordinates in a supercell
    much like that of SIESTA.
    
    This geometry class is however not restricted to SIESTA as it 
    is a general class to retain coordinates and the cell structure.
    
    All lengths are assumed to be in units of Angstrom.
    
    Parameters
    ----------
    cell  : array_like
        cell vectors in a 3x3 matrix.
        ``cell[i,:]`` is the cell vector along the i'th direction.
    xa    : array_like
        atomic coordinates in a Nx3 matrix.
        ``xa[i,:]`` is the atomic coordinate of the i'th atom.
        This atomic coordinate need not be inside the unit-cell.
    dR    : (2.5) float, optional
        The geometry's maximum orbital range. All orbitals are 
        assumed localised on the atomic centers. 
    n_orb : (1) integer/array_like, optional
        Number of orbitals per atom. If a single integer
        is supplied all atoms have the same number of orbitals,
        whereas providing a array will set the number of orbitals
        individually.
    update_sc : (False), boolean, optional
        If ``False`` it will initialise size of the super-cell to
        be one connection in all directions.
        If ``True`` it will calculate the super-cell size based
        on ``dR``.

    Attributes
    ----------
    cell : (3,3) ndarray
        Cell vectors.
    na_u : integer
        Number of atoms.
    xa   : (na_u,3) ndarray
        Atomic coordinates.
    lasto: (na_u+1) 
        Last orbital of the equivalent atom (this is offset by one)
        Hence ``lasto[0]`` is always ``0`` and ``lasto[1]`` is the
        number of orbitals on the first atom.
    no_u : integer
        Total number of orbitals 
    dR   : float
        Maximum orbital range.
    proximity: (None), integer
        Limits the search space for large geometries when finding the
        closests atoms.
        ``proximity`` narrows the search to the ``+-proximity`` nearest atoms.
        If ``None`` it will search all atoms.
    """
    def __init__(self,cell,xa,dR=2.5,n_orb=1,update_sc=False):
        self.cell = np.asarray(cell)
        self.xa = np.asarray(xa)
        self.na_u = len(xa)
        if isinstance(n_orb,int):
            # We have a fixed number of orbitals per
            # atom
            self.lasto = np.arange(self.na_u+1) * n_orb
        else:
            # The user have specified number of orbitals
            # per atom, explicitly
            self.lasto = np.cumsum(
                np.append(np.array([0],np.int),np.asarray(n_orb,np.int)))
        self.no_u = int(self.lasto[-1])
        self.dR = dR

        # Force the calculation of the super-cells from an orbital
        # range consideration
        if update_sc: 
            self.update_sc(dR=dR)
        else:
            # We force any TB method to be periodic
            # with one supercell connection.
            # Hence any reference will copy this down
            self.update_sc(nsc=[1,1,1])

        # In case the user wishes to speed
        # up the calculation of the closest atoms
        # we allow the user to define a "proximity"
        # Which drastically can narrow the search space down
        # by only looking at the ia-proximity:ia+proximity
        # atoms.
        self.proximity = None

    @staticmethod
    def SIESTA(fname):
        """Creates a geometry from a SIESTA.nc file

        Parameters
        ----------
        fname : (string)
            A NetCDF filename from which the geometry will be read in.
            It will read in the``xa``, ``cell``, ``lasto`` and ``nsc``
            variables and return a geometry from those quantities.
        """
        nf = nc.Dataset(fname,'r')
        xa = np.asarray(nf.variables['xa'][:]) * self.Bohr
        cell = np.asarray(nf.variables['cell'][:]) * self.Bohr
        lasto = np.asarray(nf.variables['lasto'][:])
        nsc = np.asarray(nf.variables['nsc'][:])
        nf.close()
        n_orb = np.diff(lasto)
        n_orb = np.append(lasto[0],n_orb)
        # Create new geometry
        g = TBT_Geom(cell=cell,xa=xa,n_orb=n_orb)
        g.update_sc(nsc=int(nsc / 2))
        return g

    def __init_new(self,cell,xa,n_orb,update_sc=False):
        """
        Internal routine to easily handle initialization
        of a new geometry, however if the user
        requests update_sc = False
        we copy the nsc and isc_off from the local 
        copy.
        """
        g = TBT_Geom(cell,xa,dR=self.dR,n_orb=n_orb,update_sc=update_sc)
        if not update_sc:
            g.nsc = np.copy(self.nsc)
            g.isc_off = np.copy(self.isc_off)
        return g

    def update_sc(self,dR=None,nsc=None):
        """ Updates the number of supercells

        Parameters
        ----------
        dR   : (None), float
            If provided the super-cell will be calculating based on the
            atomic coordinates and the maximum orbital range.
        nsc  : (None), array_like
            If provided the super-cell will be forced to this size,
            providing ``[1,1,1]`` tells the geometry that
            interactions are connecting across one cell boundary.

        If no parameters are given ``self.update_sc()`` will
        use the saved ``self.dR`` size (as given when initialised).
        """
        if dR is None:
            # Just update the super-cell, this is
            # if the user has changed the cell size
            ddR = self.dR
        else:
            self.dR = dR
            ddR = dR
        if not nsc is None:
            # The user put in the super-cell
            self.nsc = np.copy(nsc) * 2 + 1
        else:
            nsc = np.zeros([3],np.int)
            # loop over x-y-z directions
            for d in [0,1,2]:
                # create diagonal offset
                sc = np.zeros([3],np.int)
                # We need only check in the positive direction 
                # after all, it is periodic
                i = 0
                while True:
                    i += 1
                    sc[d] = i
                    for ia in xrange(self.na_u):
                        if len(self.close_sc(ia,isc=sc,dR=ddR)) > 0:
                            nsc[d] = i
                            break
                    # No interactions to auxiliary cell,
                    # so break the search
                    if nsc[d] < i: break
            # We have now calculated the required size
            # Re-set the nsc and the supercell indices
            # (correct for super-cells)
            self.nsc = nsc * 2 + 1

        # This variable determines the supercell
        self.isc_off = np.zeros([np.prod(self.nsc),3],np.int)

        # We define the following ones like this:
        x = range(-nsc[0],nsc[0]+1)
        y = range(-nsc[1],nsc[1]+1)
        z = range(-nsc[2],nsc[2]+1)
        i = 0
        for iz in z:
            for iy in y:
                for ix in x:
                    if ix == 0 and iy == 0 and iz == 0:
                        continue
                    # Increment index
                    i += 1
                    # The offsets for the supercells in the
                    # sparsity pattern
                    self.isc_off[i,0] = ix
                    self.isc_off[i,1] = iy
                    self.isc_off[i,2] = iz

    def xyz(self,fname=None,species='H'):
        """
        Creates an xyz file for showing in visual programs
        
        Parameters
        ----------
        fname : str 
            Filename to save the xyz format in.
        species : str/list
            List of species for all the atoms.
            If a ``str`` is passed the same specie is used
            for all atoms, if a list is passed every atom has
            its designated specie.
        """
        if fname:
            # In case the species is a string we expand it
            if isinstance(species,str):
                lbl = [species] * self.na_u
            else:
                lbl = species
            with open(fname,'w') as fh:
                fh.write(str(self.na_u)+'\n\n')
                for ia in xrange(self.na_u):
                    fh.write(lbl[ia]+' {0:.5f} {1:.5f} {2:.5f}\n'.format(*self.xa[ia,:]))

    def copy(self):
        """
        Returns a copy of the object.
        """
        # Create a copy of this geometry
        return self.__init_new(np.copy(self.cell),np.copy(self.xa),
                               n_orb=np.diff(self.lasto))

    def remove(self,idx_a,update_sc=False):
        """
        Remove atoms from the geometry.

        Indices passed *MUST* be unique.

        Parameters
        ----------
        idx_a  : array_like
            indices of all atoms to be removed.
        update_sc : (False), boolean, optional
            Whether the super-cell size should be recalculated using
            ``self.dR``.
        """
        xa = np.copy(self.xa)
        # truncate atoms requested
        idx = np.setdiff1d(np.arange(self.na_u),idx_a,assume_unique=True)
        orbs = np.diff(self.lasto)[idx]
        xa = xa[idx,:]
        return self.__init_new(np.copy(self.cell),xa,
                               n_orb=orbs,
                               update_sc=update_sc)

    def tile(self,*args,**kwargs):
        """ 
        Returns a geometry tiled, i.e. copied.

        The atomic indices are retained for the base structure.

        Parameters
        ----------
        args  : (tuple) (int,int)
             A tuple consisting of two integers:
                 direction : 0, 1, 2 according to the cell-direction
                 number of tiles: number of times the structure is 
                                  repeated.
        update_sc : (False), boolean, optional

        Examples
        --------
        >>> geom = TBT_Geom(cell=[[1.,0,0],[0,1.,0.],[0,0,1.]],xa=[[0,0,0],[0.5,0,0]])
        >>> g = geom.tile((0,2))
        >>> print(g.xa)
        [[ 0.   0.   0. ]
         [ 0.5  0.   0. ]
         [ 1.   0.   0. ]
         [ 1.5  0.   0. ]]
        >>> g = geom.tile((0,2),(1,2))
        >>> print(g.xa)
        [[ 0.   0.   0. ]
         [ 0.5  0.   0. ]
         [ 1.   0.   0. ]
         [ 1.5  0.   0. ]
         [ 0.   1.   0. ]
         [ 0.5  1.   0. ]
         [ 1.   1.   0. ]
         [ 1.5  1.   0. ]]

        """
        if len(args) == 0: return self.copy()
        update_sc = False
        if 'update_sc' in kwargs: update_sc = kwargs['update_sc']
        cell = np.copy(self.cell)
        for id, r in args: 
            cell[id,:] *= r
        # Pre-allocate geometry
        # Start the repetition
        xa = np.copy(self.xa)
        orbs = np.diff(self.lasto) 
        # Our first repetition *must* be with
        # the later coordinate
        ja = 0
        frR = 1
        toR = 1
        for id, r in args:
            toR *= r
            # Copy the entire structure
            xa = np.tile(xa,(r,1))
            orbs = np.tile(orbs,(r,1))
            # Single cell displacements
            dx = np.dot(np.arange(r)[:,None],self.cell[id,:][None,:])
            # Correct the unit-cell offsets
            xa[ja:ja+self.na_u*toR,:] += np.repeat(dx,frR*self.na_u,axis=0)
            frR *= r
        # Create the geometry and return it
        return self.__init_new(cell,xa,n_orb=orbs,update_sc=update_sc)

    def repeat(self,*args,**kwargs):
        """
        Returns a geometry repeated, i.e. copied in a special way.

        The atomic indices are *NOT* retained for the base structure.

        The expansion of the atoms are basically performed using this
        algorithm:
          ja = 0
          for ia in range(self.na_u):
              for id,r in args:
                 for i in range(r):
                    ja = ia + cell[id,:] * i

        This method allows to utilise Bloch's theorem when creating
        tight-binding parameter sets for TBtrans.

        For single atom geometries this routine returns the same as
        ``self.tile``.
        
        Parameters
        ----------
        args  : (tuple) (int,int)
             A tuple consisting of two integers:
                 direction : 0, 1, 2 according to the cell-direction
                 number of tiles: number of times the structure is 
                                  repeated.
        update_sc : (False), boolean, optional

        Examples
        --------
        >>> geom = TBT_Geom(cell=[[1.,0,0],[0,1.,0.],[0,0,1.]],xa=[[0,0,0],[0.5,0,0]])
        >>> g = geom.repeat((0,2))
        >>> print(g.xa)
        [[ 0.   0.   0. ]
         [ 1.   0.   0. ]
         [ 0.5  0.   0. ]
         [ 1.5  0.   0. ]]
        >>> g = geom.repeat((0,2),(1,2))
        >>> print(g.xa)
        [[ 0.   0.   0. ]
         [ 1.   0.   0. ]
         [ 0.   1.   0. ]
         [ 1.   1.   0. ]
         [ 0.5  0.   0. ]
         [ 1.5  0.   0. ]
         [ 0.5  1.   0. ]
         [ 1.5  1.   0. ]]

        """
        if len(args) == 0: return self.copy()
        update_sc = False
        if 'update_sc' in kwargs: update_sc = kwargs['update_sc']

        # Figure out the size
        R = 1
        nsc = np.copy(self.nsc)
        cell = np.copy(self.cell)
        for id, r in args: 
            cell[id,:] *= r
            # When we repeat a cell we also remove some
            # periodicity, this should take care of 
            # this (but it will still hold the
            # periodicity for simple structures)
            if nsc[id] > 3: nsc[id] -= 2
            R *= r
        # Pre-allocate geometry
        xa = np.zeros((self.na_u*R,3),np.float)
        n_orb = np.diff(self.lasto)
        orbs = np.zeros((xa.shape[0],),np.int)
        # Start the repetition
        ja = 0
        for ia in xrange(self.na_u):
            toR = 1
            frR = 1
            for id, r in args:
                toR *= r
                # Single atom displacements
                dx = np.dot(np.arange(r)[:,None],self.cell[id,:][None,:])
                # First copy the previous coordinates
                xa[ja:ja+toR,:] = np.tile(xa[ja:ja+frR,:],(frR,1))
                # We repeat the cell displacements
                xa[ja:ja+toR,:] += np.repeat(dx,frR,axis=0)
                frR *= r
            # Add the basic atomic coordinate
            xa[ja:ja+toR,:] += self.xa[ia,:]
            orbs[ja:ja+toR] = n_orb[ia]
            ja += toR
        # Create the geometry and return it
        return self.__init_new(cell,xa,n_orb=orbs,update_sc=update_sc)

    def append(self,other,axis,update_sc=False):
        """
        Appends structure along ``axis``. This will automatically
        add the ``self.cell[axis,:]`` to all atomic coordiates in the 
        ``other`` structure before appending.

        The basic algorithm is this:
        
          >>> oxa = other.xa + self.cell[axis,:][None,:]
          >>> self.xa = np.append(self.xa,oxa)
          >>> self.cell[axis,:] += other.cell[axis,:]
          >>> self.lasto = np.append(self.lasto,other.lasto)

        NOTE: The cell appended is only in the axis that
        is appended, which means that the other cell directions
        need not conform.

        Parameters
        ----------
        other : TBT_Geom
            Other geometry class which needs to be appended
        axis  : int
            Cell direction to which the ``other`` geometry should be
            appended.
        update_sc : (False), boolean, optional
            Whether the super-cell size should be re-calculated.

        """
        xa = np.append(self.xa,
                       self.cell[axis,:][None,:] + other.xa,
                       axis=0)
        cell = np.copy(self.cell)
        cell[axis,:] += other.cell[axis,:]
        orbs = np.append(np.diff(self.lasto),np.diff(other.lasto))
        return self.__init_new(cell,xa,n_orb=orbs,update_sc=update_sc)

    def a2o(self,ia):
        """
        Returns an atomic index to the first orbital of said atom
        This is particularly handy if you want to create
        TB models with more than one orbital per atom.

        Then assigning TB parameters look something like:
        (here shown for two orbitals per atom)

        # Only nearest neighbour interactions
        dR = (.1, 2.)
        for ia in xrange(self.na_u):
            io = self.a2o(ia)
            idx_a = HUGE.close_all(ia,dR=dR)
            # first orbital on-site
            HS[io+0,self.a2o(idx_a[0])+0] = (U1 ,   1. )
            # second orbital on-site
            HS[io+1,self.a2o(idx_a[0])+1] = (U2 ,   1. )
            # orbital hopping to same orbital
            HS[io+0,self.a2o(idx_a[1])+0] = (t11,   0. )
            HS[io+1,self.a2o(idx_a[1])+1] = (t22,   0. )
            # orbital hopping to differing orbital
            HS[io+0,self.a2o(idx_a[1])+1] = (t12,   0. )
            HS[io+1,self.a2o(idx_a[1])+0] = (t12,   0. )

        """
        return self.lasto[ia]

    def coords(self,isc=[0,0,0],idx=None):
        """
        Returns the coordinates of a given super-cell.

        Parameters
        ----------
        isc   : array_like
            Returns the atomic coordinates shifted according to the integer
            parts of the cell.
        idx   : int/array_like
            Only return the coordinates of these indices

        Examples
        --------
        
        >>> geom = TBT_Geom(cell=[[1.,0,0],[0,1.,0.],[0,0,1.]],xa=[[0,0,0],[0.5,0,0]])
        >>> print(geom.coords(isc=[1,0,0])
        [[ 1.   0.   0. ]
         [ 1.5  0.   0. ]]

        """
        offset = self.cell[0,:] * isc[0] + \
            self.cell[1,:] * isc[1] + \
            self.cell[2,:] * isc[2]
        if idx is None:
            return self.xa + offset[None,:]
        else:
            return self.xa[idx,:] + offset[None,:]

    def sc_idx(self,isc):
        """
        Returns the geometry index for the supercell
        corresponding to isc ([ix,iy,iz])
        """
        asc = np.asarray(isc,np.int)
        for i in xrange(self.isc_off.shape[0]):
            if np.all(self.isc_off[i,:] == asc): return i
        raise Exception('Could not find supercell index')

    def close_sc(self,xyz_ia,isc=[0,0,0],dR=None):
        """
        Calculates which atoms are close to some atom or point
        in space, only returns so relative to a super-cell.

        This returns a set of atomic indices which are within a 
        sphere of radius ``dR``.

        If dR is a tuple/list/array it will return the indices:
        in the ranges:
           ( x <= dR[0] , dR[0] < x <= dR[1], dR[1] < x <= dR[2] )

        NOTE: This routine can be made faster by setting the
        ``self.proximity`` value.

        Parameters
        ----------
        xyz_ia  : coordinate/index
            Either a point in space or an index of an atom.
            If an index is passed it is the equivalent of passing
            the atomic coordinate ``self.close_sc(self.xa[xyz_ia,:])``.
        isc     : ([0,0,0]), array_like, optional
            The super-cell which the coordinates are checked in.
        dR      : (None), float/tuple of float
            The radii parameter to where the atomic connections are found.
            If ``dR`` is an array it will return the indices:
            in the ranges:
               ``( x <= dR[0] , dR[0] < x <= dR[1], dR[1] < x <= dR[2] )``
            If a single float it will return:
               ``x <= dR``

        """
        if dR is None:
            ddR = np.array((self.dR,),np.float)
        else:
            ddR = np.array((dR,),np.float).flatten()
        ioff = 0
        if isinstance(xyz_ia,int):
            # Get atomic coordinate in principal cell
            if self.proximity:
                ioff = max(0,xyz_ia-self.proximity)
                idx = np.arange(ioff,
                                min(xyz_ia+self.proximity,self.na_u))
                dxa = self.coords(isc=isc,idx = idx) - self.xa[xyz_ia,:][None,:]
            else:
                dxa = self.coords(isc=isc) - self.xa[xyz_ia,:][None,:]
        else:
            # The user has passed a coordinate
            dxa = self.coords(isc=isc) - xyz_ia[None,:]

        # Retrieve all atomic indices which are closer
        # than our delta-R
        # The linear algebra norm function could be used, but it
        # has a lot of checks, hence we do it manually
        #xaR = np.linalg.norm(dxa,axis=-1)
        xaR = (dxa[:,0]**2+dxa[:,1]**2+dxa[:,2]**2) ** .5
        del dxa # just because these arrays could be very big...
        idx = np.where(xaR <= ddR[-1])[0]
        if len(ddR) == 1:
            # We only have one designation
            return idx + ioff
        if np.any(np.diff(ddR) < 0.):
            raise ValueError('Proximity checks for several quantities '+ \
                                 'at a time requires ascending dR values.')

        # Reduce search space!
        # The more neigbours you wish to find the faster this becomes
        # We only do "one" heavy duty search,
        # then we immediately reduce search space to this subspace
        xaR = xaR[idx]
        idx[:] += ioff
        ix = [idx[np.where(xaR <= ddR[0])[0]]]
        for i in range(1,len(ddR)):
            # Search in the sub-space
            # Notice that this sub-space reduction will never
            # allow the same indice to be in two ranges (due to
            # numerics)
            tidx = np.where(np.logical_and(ddR[i-1] < xaR,xaR <= ddR[i]))[0]
            ix.append(idx[tidx])
        return ix

    def close_all(self,xyz_ia,dR=None):
        """
        Returns supercell atomic indices for all atoms connecting to ``xyz_ia``

        This heavily relies on the ``self.close_sc`` method.

        Note that if a connection is made in a neighbouring super-cell
        then the atomic index is shifted by the super-cell index times
        number of atoms.
        This allows one to decipher super-cell atoms from unit-cell atoms.

        Parameters
        ----------
        xyz_ia  : coordinate/index
            Either a point in space or an index of an atom.
            If an index is passed it is the equivalent of passing
            the atomic coordinate ``self.close_sc(self.xa[xyz_ia,:])``.
        dR      : (None), float/tuple of float
            The radii parameter to where the atomic connections are found.
            If ``dR`` is an array it will return the indices:
            in the ranges:
               ``( x <= dR[0] , dR[0] < x <= dR[1], dR[1] < x <= dR[2] )``
            If a single float it will return:
               ``x <= dR``

        """
        idx_a = None
        for s in xrange(np.prod(self.nsc)):
            no = s * self.na_u
            idx = self.close_sc(xyz_ia,self.isc_off[s,:],dR=dR)
            if isinstance(idx,list):
                # we have a list of arrays
                if idx_a is None:
                    idx_a = [ix + no for ix in idx]
                else:
                    for i,ix in enumerate(idx):
                        idx_a[i] = np.append(idx_a[i],ix + no)
            elif len(idx) > 0:
                # We can add it to the list
                # We add the atomic offset for the supercell 
                # index
                if idx_a is None:
                    idx_a = idx + s * self.na_u
                else:
                    idx_a = np.append(idx_a,idx+s*self.na_u)
        return idx_a
        

class TBT_Model(SIESTA_UNITS):
    """
    A wrapper to create zero containing sparsity patterns
    while easily implementing the symmetric sparsity pattern.
    """
    def __init__(self,geom,max_connection=None):
        self.geom = geom
        self.no_u = geom.no_u
        no_s = geom.no_u * np.prod(geom.nsc)
        # We first find the maximal number of connections per atom
        max_n = 0
        if max_connection:
            max_n = max_connection
        else:
            # Determine maximum number of connections explicitly
            for ia in xrange(geom.na_u):
                idx = geom.close_all(ia)
                max_n = max(max_n,len(idx))

        self.max_n = max_n
        self.reset()

    def _reset_sp(self):
        """ Reset the sparsity pattern """
        # To increase performance of creating
        # the TB parameters we fix the connections
        # per orbital to the maximum number of
        # connections, then later we truncate
        # Hence our ncol keeps track of how many we actually have
        self.ncol = np.zeros((self.no_u,),np.int)
        self.ptr = np.cumsum(np.repeat(np.array([self.max_n],np.int),
                             self.no_u+1)) - self.max_n
        self.nnzs = 0
        self.col = np.empty((self.ptr[-1],),np.int)

        self._finalized = False

    def reset(self,dtype=np.float):
        """
        This lets the HS size be set by the user
        """
        # I know that this is not the most efficient way to
        # access a C-array, however, for constructing a
        # sparse pattern, it should be faster if memory elements
        # are closer... 
        # Hence, this choice of having H and S like this

        self._reset_sp()
        # Initialize HS size
        self.HS = np.empty((self.ptr[-1],2),dtype=dtype)

    def finalize(self):
        """ 
        Disables the ability to extend this TB sparsity pattern
        """
        if self._finalized: return
        self._finalized = True
        ptr = self.ncol[0]
        if np.unique(self.col[:ptr]).shape[0] != ptr:
            raise ValueError('You cannot have two hoppings between '+
                             'the same orbitals.')
        if self.no_u > 1:
            # We truncate all the connections
            for io in xrange(1,self.no_u):
                cptr = self.ptr[io]
                # Update actual pointer position
                self.ptr[io] = ptr
                no = self.ncol[io]
                self.col[ptr:ptr+no]  = self.col[cptr:cptr+no]
                self.HS[ptr:ptr+no,:] = self.HS[cptr:cptr+no,:]
                # we also assert no two connections
                if np.unique(self.col[ptr:ptr+no]).shape[0] != no:
                    raise ValueError('You cannot have two hoppings between '+
                                     'the same orbitals.')
                ptr += no
        # Correcting the size of the pointer array
        self.ptr[self.no_u] = ptr
        if ptr != self.nnzs:
            raise ValueError('Error in creating the TB parameter space')
        # Truncate values to correct size
        self.HS = self.HS[:self.nnzs,:]
        self.col = self.col[:self.nnzs]
        # Deleting the variable
        # will error out in _setitem when
        # it is referenced :)
        del self.nnzs

        # Sort the indices (THIS IS A REQUIREMENT!)
        for io in xrange(self.no_u):
            ptr = self.ptr[io]
            no  = self.ncol[io]
            # Sort the indices
            si = np.argsort(self.col[ptr:ptr+no])
            self.col[ptr:ptr+no]  = self.col[ptr+si]
            self.HS[ptr:ptr+no,:] = self.HS[ptr+si,:]

    def __setitem__(self,key,val):
        """
        Override set item for slicing operations and enables easy setting of TB parameters
        in a sparse matrix

        It does allow fancy slicing in both dimensions with limited usability
        
        Ok, it is not pretty, it is not fast, but it works!
        """
        # unpack index
        i , j = key
        if not isinstance(i,int):
            # Recursively handle index,index = val
            # designators.
            if len(i) > 1: 
                if len(i) != len(j):
                    raise ValueError('Size of LHS and RHS are not equal, error on input [LHS,RHS]')
                for ii,jj in zip(i,j):
                    self[int(ii),jj] = val
                return
            i = int(i[0])
        # step pointer of all above this
        ptr  = self.ptr[i]
        ncol = self.ncol[i]
        jj = np.asarray([j]).flatten()
        lj = jj.shape[0]
        if ncol > 0:
            # Checks whether any values in either array exists
            idx = np.intersect1d(jj,self.col[ptr:ptr+ncol],assume_unique=True)
        else:
            idx = []
        if len(idx) != 0:
            
            # Here we truncate jj to the "new" values,
            # this allows us to both overwrite and add new values to the sparsity pattern
            # (simultaneously)
            jj = np.setdiff1d(jj, idx, assume_unique=True)
            lj = jj.shape[0]

            # the values corresponding to idx already exists, we overwrite that value
            if isinstance(j,int):
                ix = ptr + np.where(j == self.col[ptr:ptr+ncol])[0][0]
                self.HS[ix,:] = val
            else:
                # remember that idx is the intersection values
                for ij in idx:
                    ix = ptr + np.where(ij == self.col[ptr:ptr+ncol])[0][0]
                    self.HS[ix,:] = val

            # if no new values are left we return immediately
            if lj == 0: return

        if self.col.shape[0] < self.nnzs + lj:
            print('Shape. col '+str(self.col.shape[0]) + ' and non-zero elements '+str(self.nnzs))
            raise ValueError('Have you changed the sparsity pattern while editing '+
                             'the TB parameters? This is not allowed.\n'+
                             'Or maybe you have initialized max_connection too small, try increasing it.')
        # Step to the placement of the new values
        ptr += ncol
        # set current value
        self.col[ptr:ptr+lj]  = jj
        self.HS[ptr:ptr+lj,:] = val
        self.ncol[i] += lj
        # Increment number of non-zero elements
        self.nnzs += lj

    def tocsr(self):
        """
        Returns a csr sparse matrix for both the Hamiltonian
        and the overlap matrix
        """
        try:
            if self._finalized: pass
        except:
            self.finalize()
        # Create csr sparse formats.
        # We import here as the user might not want to
        # rely on this feature.
        import scipy.sparse as spar
        if self.HS.shape[1] == 1:
            return spar.csr_matrix((self.HS[:,0],self.col,self.ptr))
        return (spar.csr_matrix((self.HS[:,0],self.col,self.ptr)), \
                    spar.csr_matrix((self.HS[:,1],self.col,self.ptr)))

    def _save_sparsity(self,nf,zlib=0):
        """
        Saves the sparsity format if it does not currently exist
        in the file/group.
        Else it will check that the quantitites are the same.
        """
        self.finalize()

        cmp_lvl = zlib
        z_lib = zlib > 0

        if 'n_col' in nf.variables:
            # Check that the sparsity is the same
            if np.any(nf.variables['n_col'][:] != self.ncol):
                raise ValueError('The sparsity pattern is not the same')
            if np.any(nf.variables['list_col'][:] != self.col + 1):
                raise ValueError('The sparsity pattern is not the same')
        else:
            # Create the sparsity pattern
            if not 'nnzs' in nf.dimensions:
                nf.createDimension('nnzs',self.col.shape[0])
            
            v = nf.createVariable('n_col','i4',('no_u',))
            v.info = "Number of non-zero elements per row"
            v[:] = self.ncol
            v = nf.createVariable('list_col','i4',('nnzs',),
                                  zlib=z_lib,complevel=cmp_lvl,
                                  chunksizes=(len(self.col),))
            
            v.info = "Supercell column indices in the sparse format"
            v[:] = self.col[:] + 1

    def save(self,fname='SIESTA.nc',Ef=0.,zlib=0):
        """
        Saves the current information in the 'fname'
        to be ready to be read in by tbtrans
        """

        self.finalize()

        if os.path.isfile(fname):
            raise Exception('File: '+fname+' already exists, we do not allow overwriting.')

        nf = nc.Dataset(fname,'w',format='NETCDF4')

        cmp_lvl = zlib
        z_lib = zlib > 0

        # Create initial dimensions
        nf.createDimension('one',1)
        nf.createDimension('n_s',np.prod(self.geom.nsc))
        nf.createDimension('xyz',3)
        nf.createDimension('no_s',np.prod(self.geom.nsc)*self.no_u)
        nf.createDimension('no_u',self.no_u)
        nf.createDimension('spin',1)
        nf.createDimension('na_u',self.geom.na_u)

        # Create common variables
        v = nf.createVariable('nsc','i4',('xyz',))
        v.info = 'Number of supercells in each unit-cell direction'
        v = nf.createVariable('lasto','i4',('na_u',))
        v.info = 'Last orbital of equivalent atom'
        v = nf.createVariable('Ef','f8',('one',))
        v.info = 'Fermi level'
        v.unit = 'Ry'
        v = nf.createVariable('Qtot','f8',('one',))
        v.info = 'Total charge'
        v = nf.createVariable('xa','f8',('na_u','xyz'))
        v.info = 'Atomic coordinates'
        v.unit = 'Bohr'
        v = nf.createVariable('cell','f8',('xyz','xyz'))
        v.info = 'Unit cell'
        v.unit = 'Bohr'

        # Create attribute
        nf.method = 'python'

        sp = nf.createGroup('SPARSE')
        self._save_sparsity(sp,zlib=zlib)

        #sp.createDimension('nnzs',H.getnnz())
        v = sp.createVariable('isc_off','i4',('n_s','xyz'))
        v.info = "Index of supercell coordinates"
        v = sp.createVariable('S','f8',('nnzs',),
                              zlib=z_lib,complevel=cmp_lvl,
                              chunksizes=(len(self.col),))
        v.info = "Overlap matrix"
        v = sp.createVariable('H','f8',('spin','nnzs'),
                              zlib=z_lib,complevel=cmp_lvl,
                              chunksizes=(1,len(self.col)))
        v.info = "Hamiltonian"
        v.unit = "Ry"

        # We need to fake some BZ sampling... 
        # This will probably force the
        # user to utilize the check-kgrid F
        # in the electrodes.... well....
        st = nf.createGroup('SETTINGS')
        v = st.createVariable('ElectronicTemperature','f8',('one',))
        v.info = "Electronic temperature used for smearing DOS"
        v.unit = "Ry"
        v = st.createVariable('BZ','i4',('xyz','xyz'))
        v.info = "Grid used for the Brillouin zone integration"
        v = st.createVariable('BZ_displ','i4',('xyz',))
        v.info = "Monkhorst-Pack k-grid displacements"
        v.unit = "b**-1"

        # Save quantities
        nf.variables['nsc'][:] = self.geom.nsc
        nf.variables['lasto'][:] = self.geom.lasto[1:]
        nf.variables['Ef'][:] = Ef / self.Ry
        nf.variables['Qtot'][:] = self.no_u
        
        nf.variables['xa'][:,:] = self.geom.xa[:,:] / self.Bohr
        nf.variables['cell'][:,:] = self.geom.cell[:,:] / self.Bohr

        # Get sparse format
        sp.variables['isc_off'][:] = self.geom.isc_off

        # Save data
        sp.variables['H'][:] = self.HS[:,0] / self.Ry
        sp.variables['S'][:] = self.HS[:,1]

        # Just to ensure that it is not a Gamma
        # point calculation
        st.variables['BZ'][:] = np.identity(3) * 2
        st.variables['BZ_displ'][:] = np.zeros([3],np.float)

        st.variables['ElectronicTemperature'][:] = 0.025 / self.Ry

        nf.close()

class TBT_dH(TBT_Model):
    """
    Specific class to create dH input's for tbtrans.
    """
    def reset(self,dtype=np.float):
        """
        This lets the HS size be set by the user
        """
        # I know that this is not the most efficient way to
        # access a C-array, however, for constructing a
        # sparse pattern, it should be faster if memory elements
        # are closer... 
        # Hence, this choice of having H and S like this

        self._reset_sp()
        # Initialize HS size
        self.HS = np.empty((self.ptr[-1],1),dtype=dtype)

    @staticmethod
    def _add_lvl(nf,lvl=0):
        """
        Simply adds and returns a group if it does not
        exist it will be created
        """
        slvl = 'LEVEL-'+str(lvl)
        if not slvl in nf.groups:
            gr = nf.createGroup(slvl)
            if lvl in [2,4]:
                gr.createDimension('nkpt',None)
                v = gr.createVariable('kpt','f8',('nkpt','xyz'))
                v.info = 'k-points for dH values'
                v.unit = 'b**-1'
            if lvl in [3,4]: 
                gr.createDimension('ne',None)
                v = gr.createVariable('E','f8',('ne',))
                v.info = 'Energy points for dH values'
                v.unit = 'Ry'
        else:
            gr = nf.groups[slvl]
        return gr
        
    def save(self,fname,kpt=None,E=None,delete=False,zlib=0):
        """
        Simple routine for creating/saving dH file for input to tbtrans

        Important input are kpt and E.
        If none are provided it is a level 1.
        If kpt is provided and E is not it is a level 2.
        If E is provided and kpt is not it is a level 3.
        If both are provided it is a level 4.

        """
        # Be sure to have the sparsity pattern shrunk to the correct size
        self.finalize()

        if os.path.isfile(fname) and not delete:
            # The file already exists, so we append
            nf = nc.Dataset(fname,'a')
        else:
            nf = nc.Dataset(fname,'w',format='NETCDF4')
            nf.createDimension('xyz',3)
            nf.createDimension('no_u',self.no_u)
        
        cmp_lvl = zlib
        z_lib = zlib > 0
    
        # find level
        if not kpt is None:
            if not E is None:
                # Level 4 
                lvl = 4
                dims = ('nkpt','ne','nnzs')
                chk_size = (1,1,len(self.col))
            else:
                # Level 2
                lvl = 2
                dims = ('nkpt','nnzs')
                chk_size = (1,len(self.col))
        elif not E is None:
            # Level 3
            lvl = 3
            dims = ('ne','nnzs')
            chk_size = (1,len(self.col))
        else:
            # Level 1
            lvl = 1
            dims = ('nnzs',)
            chk_size = (len(self.col),)

        # Add level
        glvl = self._add_lvl(nf,lvl)

        E_warn = False
        if lvl in [3,4]:
            all_E = np.array(glvl.variables['E'][:]) * self.Ry

            # Get energy index
            iE = 0
            if len(all_E) > 0:
                iE = np.argmin(np.abs(all_E - E))
                if abs(all_E[iE] - E) > 0.0001: # 0.1 meV accuracy...
                    # We add a new index
                    iE = len(all_E)
                else:
                    E_warn = True

        k_warn = False
        if lvl in [2,4]:
            all_k = np.array(glvl.variables['kpt'][:])
            
            # Get k-point index
            ik = 0
            if len(all_k) > 0:
                ik = np.argmin(np.sum(np.abs(all_k - kpt[None,:]),axis=-1))
                if abs(np.sum(np.abs(all_k[ik,:] - kpt))) > 0.0001:
                    # We add a new index
                    ik = len(all_k)
                else:
                    k_warn = True
                    
        if lvl == 4 and k_warn and E_warn and False:
            # As soon as we have put the second k-point and the first energy
            # point, this warning will proceed...
            # I.e. even though the variable has not been set, it will WARN
            # Hence we out-comment this for now...
            print('WARNING: Overwriting k-point {0} and energy point {1} correction.'.format(ik,iE))
        elif lvl == 3 and E_warn:
            print('WARNING: Overwriting energy point {0} correction.'.format(iE))
        elif lvl == 2 and k_warn:
            print('WARNING: Overwriting k-point {0} correction.'.format(ik))
        
        # Check that the sparsity pattern for the Hamiltonian
        # matches the sparsity found in the file (if it exists)
        self._save_sparsity(glvl,zlib=zlib)

        # Save the Hamiltonian
        # Check for data type
        if np.iscomplexobj(self.HS):
            # We have it complex denoted by the user
            if not 'RedH' in glvl.variables:
                rH = glvl.createVariable('RedH','f8',dims,
                                         zlib=z_lib,complevel=cmp_lvl,
                                         chunksizes=chk_size)
                rH.info = 'Change in Hamiltonian'
                rH.unit = 'Ry'
                cH = glvl.createVariable('ImdH','f8',dims,
                                         zlib=z_lib,complevel=cmp_lvl,
                                         chunksizes=chk_size)
                cH.info = 'Change in Hamiltonian'
                cH.unit = 'Ry'
            else: 
                rH = glvl.variables['RedH']
                cH = glvl.variables['ImdH']
            # Save dH
            if   1 == lvl:
                rH[:] = self.HS[:,0].real / self.Ry
                cH[:] = self.HS[:,0].imag / self.Ry
            elif 2 == lvl:
                glvl.variables['kpt'][ik,:] = kpt[:]
                rH[ik,:] = self.HS[:,0].real / self.Ry
                cH[ik,:] = self.HS[:,0].imag / self.Ry
            elif 3 == lvl:
                glvl.variables['E'][iE] = E / self.Ry
                rH[iE,:] = self.HS[:,0].real / self.Ry
                cH[iE,:] = self.HS[:,0].imag / self.Ry
            elif 4 == lvl:
                glvl.variables['kpt'][ik,:] = kpt[:]
                glvl.variables['E'][iE] = E / self.Ry
                rH[ik,iE,:] = self.HS[:,0].real / self.Ry
                cH[ik,iE,:] = self.HS[:,0].imag / self.Ry
        else:
            # We have it complex denoted by the user
            if not 'dH' in glvl.variables:
                rH = glvl.createVariable('dH','f8',dims,
                                         zlib=z_lib,complevel=cmp_lvl,
                                         chunksizes=chk_size)
                rH.info = 'Change in Hamiltonian'
                rH.unit = 'Ry'
            else: 
                rH = glvl.variables['dH']
            # Save dH
            if   1 == lvl:
                rH[:] = self.HS[:,0] / self.Ry
            elif 2 == lvl:
                glvl.variables['kpt'][ik,:] = kpt[:]
                rH[ik,:] = self.HS[:,0] / self.Ry
            elif 3 == lvl:
                glvl.variables['E'][iE] = E / self.Ry
                rH[iE,:] = self.HS[:,0] / self.Ry
            elif 4 == lvl:
                glvl.variables['kpt'][ik,:] = kpt[:]
                glvl.variables['E'][iE] = E / self.Ry
                rH[ik,iE,:] = self.HS[:,0] / self.Ry

        # Cleanup
        nf.close()

# According to 
#  PRB. 81, 245402 (2010)
# we define A-G different sets of
# TB parameters for graphene.
# Our models will from this create a 
# TB input file for tbtrans
_TB_graphene = {
    # set A
    'A' : {
        # Nearest neighbour
        'n1' : -2.7, 
        # next nearest neighbour
        'n2' : 0. ,
        # next-next nearest neighbour
        'n3' : 0. ,
        # overlap (same as neigbour intgers)
        's1' : 0. ,
        's2' : 0. ,
        's3' : 0. ,
        # hopping to an armchair edge 
        'eA' : -2.7,
        'eZ' : -2.7,
        # Hubbard U
        'U'  : 0. ,
        },
    }
# Define set B
_TB_graphene['B'] = copy.deepcopy(_TB_graphene['A'])
_TB_graphene['B']['U'] = 2.0
# Define set C
_TB_graphene['C'] = copy.deepcopy(_TB_graphene['B'])
_TB_graphene['C']['n2'] = -0.2
# Define set D
_TB_graphene['D'] = copy.deepcopy(_TB_graphene['C'])
_TB_graphene['D']['n3'] = -0.18
# Define set E
_TB_graphene['E'] = copy.deepcopy(_TB_graphene['D'])
_TB_graphene['E']['eA'] = 1.06 * _TB_graphene['E']['n1']
_TB_graphene['E']['eZ'] = 1.03 * _TB_graphene['E']['n1']
# Define set F
_TB_graphene['F'] = copy.deepcopy(_TB_graphene['D'])
_TB_graphene['F'].update({
        'n2' : -0.09 ,
        'n3' : -0.27 ,
        's1' : 0.11 ,
        's2' : 0.045,
        's3' : 0.065,
        })
# Define set G
_TB_graphene['G'] = copy.deepcopy(_TB_graphene['D'])
_TB_graphene['G'].update({
        'n1' : -2.97 ,
        'n2' : -0.073,
        'n3' : -0.33 ,
        's1' : 0.073,
        's2' : 0.018,
        's3' : 0.026,
        'U'  : 0.   ,
        })

# Define a generic geometry for a square graphene unit-cell
# To create any arbitrary unit-cell, simple use the repeat
# function. :)
def graphene_uc(alat=1.42):
    """
    Returns a generic graphene unit-cell with user set lattice
    parameter.
    """
    sq3h  = 3.**.5 * 0.5
    gr = TBT_Geom(xa=np.array([[ 0.,   0., 0.],
                               [ 2.,   0., 0.],
                               [0.5, sq3h, 0.],
                               [1.5, sq3h, 0.] ],np.float),
                  cell=np.array([[3.,     0.,  0.],
                                 [0., 2*sq3h,  0.],
                                 [0.,     0., 10.]],np.float),
                  dR=2.05) # third nearest neighbour
    gr.xa   *= alat
    gr.cell *= alat
    gr.dR   *= alat
    gr.update_sc()
    return gr

def TB_save(fname,Geom,TB = _TB_graphene['D'],alat=1.42):
    """ 
    Creates a TB SIESTA.nc file with a system of a geometry.
    It will automatically create a sparsity pattern based
    on the tight-binding parameter set provided through TB.
    """

    sq3h  = 3.**.5 * 0.5

    # Print out the differences with respect to the first
    #print('dR from 0: ',np.linalg.norm(Geom.xa-Geom.xa[0,:][None,:],axis=-1))

    # Create the sparsity pattern.
    # The regular scipy sparse patterns does not 
    # allow entering elements with zero value.
    # Hence we need to build it our-selves :(

    # In our one orbital model this will do
    HS = TBT_Model(Geom)

    # When setting the hopping and overlap you do it by 
    # a tuple assignment
    # Hence:
    #   HS[i,j] = (H,S)
    # means that the i'th orbital connecting with the j'th
    # has hopping energy H and overlap S

    # Create tuple of connection ranges (this is for graphene)
    dR   = ( alat*0.5 , alat+0.1 , 2*sq3h*alat+0.1 , 2*alat+0.1 )
    on   = (TB['U'] ,1.)
    nn   = (TB['n1'],TB['s1'])
    nnn  = (TB['n2'],TB['s2'])
    nnnn = (TB['n3'],TB['s3'])

    # We add all hoppings
    for ia in xrange(Geom.na_u):
        # Retrieve all hoppings (in one go)
        idx_a = Geom.close_all(ia,dR=dR)
        # set all on-site hoppings
        HS[ia,idx_a[0]] = on
        # set all nearest hoppings
        HS[ia,idx_a[1]] = nn
        # set all next-nearest hoppings
        HS[ia,idx_a[2]] = nnn
        # set all next-next-nearest hoppings
        HS[ia,idx_a[3]] = nnn

    # This concludes the sparsity pattern
    # Save it
    HS.save(fname,Ef=TB['U'])

def TB_square():
    """
    This simple example is the same as given in the manual
    for TBtrans.
    So follow the explanations there carefully and you should 
    be able to handle arbitrary systems
    """
    
    # Create a square unit cell with
    # nearest neighbour interactions,
    # and interatomic separation of 1. Ang
    cell = np.identity(3,np.float)
    cell[2,2] = 2.
    SQ = TBT_Geom(xa=np.zeros([1,3],np.float),
                  cell=cell, dR=1.1)
    
    # Extend the square lattice to a
    # 2 by 1 electrode [x by y]
    el  = SQ.repeat((0,2))
    # Create the device by making 1 by 3 times the electrode
    # [ x by y ]
    dev = el.tile((1,3))
    
    # Create the TB models
    TB_el  = TBT_Model(el)
    TB_dev = TBT_Model(dev)
    
    # set TB parameters
    # In the following we set the TB 
    # manually, however, further down we
    # also create them in an easier way
    # The point is to learn how the sparsity pattern
    # is setup.

    U  =  0.
    t1 = -0.5
    # electrode:
    #   on-site
    for io in range(el.no_u):
        TB_el[io,io] = (U,1.)
    #  1 -> 2
    TB_el[0,1] = (t1,0.)
    #  2 -> 1
    TB_el[1,0] = (t1,0.)
    #  1 -> 2 in super-cell [-1,0] and [1,0]
    # First we get supercell offset for the [-1,0] cell
    sc = el.sc_idx([-1,0,0]) * el.no_u
    TB_el[0,sc+1] = (t1,0.)
    sc = el.sc_idx([1,0,0]) * el.no_u
    TB_el[1,sc+0] = (t1,0.)
    # 1 -> 1, 2 -> 2
    #  in super-cell [0,-1] and [0,1]
    sc = el.sc_idx([0,-1,0]) * el.no_u
    TB_el[0,sc+0] = (t1,0.)
    TB_el[1,sc+1] = (t1,0.)
    sc = el.sc_idx([0,1,0]) * el.no_u
    TB_el[0,sc+0] = (t1,0.)
    TB_el[1,sc+1] = (t1,0.)
    
    # This finalizes the TB parameters for a
    # unit-cell with 2 atoms.
    # To recap, each atom connects with 4 
    # neighbouring atoms totalling in us
    # needing to set 8 elements (and we did!)

    # Here I show how the exact same thing can
    # be achieved by using atomic coordinates
    # to determine the integral hoppings,
    # first we define the range of hoppings
    #  on-site hoppings must be of atoms within 0.1 Ang of
    #          other atoms
    #  nearest neighbour hoppings must be of atoms within 1.1 Ang
    #          of other atoms
    #     on-site , nearest neighbour
    dR = (  0.1   ,     1.1          )
    # NOTE, this below loop does EVERYTHING you did above!
    on = (U ,1.)
    nn = (t1,0.)
    for ia in xrange(el.na_u):
        idx_a = el.close_all(ia,dR=dR)
        # now idx_a is a list of two indices
        #  idx_a[0] is an index list containing all atoms 
        #           connecting to 'ia' within 0.1 Ang
        #  idx_a[1] is an index list containing all atoms
        #           connection to 'ia' within 1.1 Ang
        # Hence we can set the hopping integrals like this
        TB_el[ia,idx_a[0]] = on
        TB_el[ia,idx_a[1]] = nn

    # Now we just do the same thing for the device
    for ia in xrange(dev.na_u):
        idx_a = dev.close_all(ia,dR=dR)
        # now idx_a is a list of two indices
        #  idx_a[0] is an index list containing all atoms 
        #           connecting to 'ia' within 0.1 Ang
        #  idx_a[1] is an index list containing all atoms
        #           connection to 'ia' within 1.1 Ang
        # Hence we can set the hopping integrals like this
        TB_dev[ia,idx_a[0]] = on
        TB_dev[ia,idx_a[1]] = nn
        
    # And DONE, you have now created your first input for
    # tbtrans with a TB model of a square lattice

    # However, there is one problem...
    # tbtrans cannot handle too small problems.
    # For this square lattice it is too small, and we need it
    # to be wider for it to run (or one could increase the 
    # orbital range)

    # Here we correct the example to a wider system so it can be
    # run by tbtrans (it just needs to be [4 by 3]
    el  = SQ.repeat((0,4))
    dev = el.tile((1,3))
    TB_el = TBT_Model(el)
    for ia in xrange(el.na_u):
        idx_a = el.close_all(ia,dR=dR)
        TB_el[ia,idx_a[0]] = on
        TB_el[ia,idx_a[1]] = nn
    TB_dev = TBT_Model(dev)
    for ia in xrange(dev.na_u):
        idx_a = dev.close_all(ia,dR=dR)
        TB_dev[ia,idx_a[0]] = on
        TB_dev[ia,idx_a[1]] = nn
    # Now save the TB models to corresponding NetCDF-4 files
    TB_el.save('SQUARE_EL.nc')
    TB_dev.save('SQUARE_DEV.nc')


    ############################
    #    To showcase the dH    #
    #    method introduced we  #
    #  do these small changes  #
    ############################
    print('Setting up dH model for SQUARE calculation cell...')

    # Create new TB model of sub-object TBT_dH
    TB_dH = TBT_dH(dev)
    # the dH method can be re-set several times
    TB_dH.reset()

    ########## LEVEL-1 ############
    #       REAL correction       #
    ###############################
    for ia in xrange(dev.na_u):
        TB_dH[ia,ia] = 0.1
    TB_dH.save('SQUARE_dH.nc')

    # Initialize the k-point for level 2 and 4
    kpt = np.zeros((3,),np.float)

    ########## LEVEL-2 ############
    #      COMPLEX correction     #
    #    5 k-points               #
    ###############################
    TB_dH.reset(dtype=np.complex)
    for ik in xrange(5):
        kpt[0] = ik * 0.5 / 4
        if ik == 4: kpt[0] = (ik-1) * 0.5 / 4
        for ia in xrange(dev.na_u):
            TB_dH[ia,ia] = 0.1 + 1j*0.001 * ik
        TB_dH.save('SQUARE_dH.nc',kpt=kpt)

    ########## LEVEL-3 ############
    #        REAL correction      #
    #  100 energy-points          #
    ###############################
    TB_dH.reset()
    for iE in xrange(100):
        E = (iE-99.5)*0.025
        for ia in xrange(dev.na_u):
            TB_dH[ia,ia] = np.exp(-E**2) * 1e-1
        TB_dH.save('SQUARE_dH.nc',E=E)

    ########## LEVEL-4 ############
    #      COMPLEX correction     #
    #    5 k-points               #
    #  100 energy-points          #
    ###############################
    TB_dH.reset(dtype=np.complex)
    for ik in xrange(5):
        kpt[0] = ik * 0.5 / 4
        if ik == 4: kpt[0] = (ik-1) * 0.5 / 4
        for iE in xrange(100):
            E = (iE-49.5)*0.025
            for ia in xrange(dev.na_u):
                TB_dH[ia,ia] = 0.1 + 1j*np.exp(-E**2) * 1e-2
            TB_dH.save('SQUARE_dH.nc',E=E,kpt=kpt)

    # Done, the TB model for dH has now been saved with
    # several different methods.
    print('Done creating dH model permutations...')

if __name__ == '__main__':

    # This example code produces several TB NetCDF-4 files
    alat = 1.42
    sq3h  = 3.**.5 * 0.5
    GR_na_u = graphene_uc(alat).na_u

    # create the simple square hopping integral
    TB_square()

    #TB_save('ELEC_zz.nc',graphene_uc(alat))
    
    # We create all TB paramaters for a zz edge 
    # pristine graphene sample:
    for TB in ['A','B','C','D','E','F','G']:
        TB_save('ELEC_' + TB + '_zz.nc',
                graphene_uc(alat) , TB = _TB_graphene[TB], alat=alat)
        TB_save('DEV_'  + TB + '_zz.nc',
                graphene_uc(alat).tile((1,5)) , TB = _TB_graphene[TB],alat=alat)

    # For the below examples we use the D set and a 
    # lattice constant of 1.42
    TB   = _TB_graphene['D']
    on   = np.array([TB['U'] ,   1.  ])
    nn   = np.array([TB['n1'],TB['s1']])
    nnn  = np.array([TB['n2'],TB['s2']])
    nnnn = np.array([TB['n3'],TB['s3']])

    # Just for fun, create a graphene flake with a hole in it
    # This is essentially an anti-dot lattice with pristine electrodes
    Nx = 10 ; Ny = 30
    print('Repeating graphene UC to flake with hole containing '+str(Nx*Ny*GR_na_u)+' atoms...')
    HOLE = graphene_uc(alat).repeat((0,Nx)).tile((1,Ny))
    HOLE.update_sc(nsc=[1,1,0])
    # Remove a hole in the structure
    # We take some atom in the middle of the structure
    mid_atom = GR_na_u * (Nx * Ny) / 2
    # Get all indices for all super-cell atoms within 12 angstrom
    idx_a = HOLE.close_all(mid_atom,dR=12.)
    # Convert to unit-cell atomic indices
    idx_a %= HOLE.no_u
    # remove dublicates (in case the user makes a too large hole)
    idx_a = np.unique(idx_a)
    print('Removing '+str(len(idx_a))+' atoms...')
    HOLE = HOLE.remove(idx_a)
    HS = TBT_Model(HOLE, max_connection = 20)
    dR = ( alat*0.5 , alat+0.1 , 2*sq3h*alat+0.1 , 2*alat+0.1 )
    print('Creating TB parameter Hamiltonian and overlap...')
    for ia in xrange(HOLE.na_u):
        idx_a = HOLE.close_all(ia,dR=dR)
        HS[ia,idx_a[0]] = on
        HS[ia,idx_a[1]] = nn
        HS[ia,idx_a[2]] = nnn
        HS[ia,idx_a[3]] = nnnn
    print('Converting to CSR sparsity format and saving NetCDF file...')
    HS.save('HOLE_D_zz.nc',Ef=TB['U'])

    # Save an xyz file to let the user view the geometry
    HOLE.xyz('HOLE_zz.xyz',species='C')

    # Just for fun, create a HUGE graphene flake
    print('Starting time... '+str(datetime.datetime.now().time()))
    Nx = 40 ; Ny = 60
    print('Repeating graphene UC to huge flake containing '+str(Nx*Ny*GR_na_u)+' atoms...')
    HUGE = graphene_uc(alat).repeat((0,Nx)).tile((1,Ny))
    HUGE.update_sc(nsc=[1,1,0])
    # This will reduce setup time, it only takes into consideration
    # the closest atoms (in terms of index) corresponding to this
    # "width". I.e. proximity = 10 means that close_all
    # only takes these indices into consideration: 
    #   xa[idx-10:idx+10,:]
    # If in doubt, do not use this flag...
    HUGE.proximity = Nx * GR_na_u * 2
    HS = TBT_Model(HUGE , max_connection = 20)
    dR = ( alat*0.5 , alat+0.1 , 2*sq3h*alat+0.1 , 2*alat+0.1 )
    print('Creating TB parameter Hamiltonian and overlap...')
    for ia in xrange(HUGE.na_u):
        idx_a = HUGE.close_all(ia,dR=dR)
        HS[ia,idx_a[0]] = on
        HS[ia,idx_a[1]] = nn
        HS[ia,idx_a[2]] = nnn
        HS[ia,idx_a[3]] = nnnn
    print('Converting to CSR sparsity format and saving NetCDF file...')
    HS.save('HUGE_D_zz.nc',Ef=TB['U'])

    HUGE.xyz('HUGE_zz.xyz',species='C')

    print('Ending time... '+str(datetime.datetime.now().time()))
